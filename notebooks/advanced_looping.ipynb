{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a556cb79-66cb-4654-8bef-47fcb57b3b1b",
   "metadata": {},
   "source": [
    "# Advanced Event 'Loops'\n",
    "\n",
    "Iterating in python is relatively slow, though it can be useful for prototyping.\n",
    "\n",
    "First, lets declare a projection function that takes an event and projects out the neutrino energy from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8d13ee-10f5-43cc-9db5-fed7a99be0f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyNUISANCE as pn\n",
    "import pyProSelecta as pps\n",
    "\n",
    "evs = pn.EventSource(\"dune_argon_sf_10mega.nuwro.pb.gz\")\n",
    "if not evs:\n",
    "    print(\"Error: failed to open input file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8642e3a-b18b-4a5a-b365-a74d66a8304d",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "NUISANCE provides the `FrameGen` facility for declaring functional event processors and then executing them in batch. Lets see an example of how it works. We include the `limit` call to stop the internal loop running over the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d589e88-3ac5-4762-8843-609f2a3b6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------\n",
      " | evt# | cvw |\n",
      " --------------\n",
      " |    0 |   1 |\n",
      " |    1 |   1 |\n",
      " |    2 |   1 |\n",
      " |    3 |   1 |\n",
      " |    4 |   1 |\n",
      " |    5 |   1 |\n",
      " |    6 |   1 |\n",
      " |    7 |   1 |\n",
      " |    8 |   1 |\n",
      " |    9 |   1 |\n",
      " --------------\n"
     ]
    }
   ],
   "source": [
    "print(pn.FrameGen(evs).limit(10).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535baf75-e504-4d8d-8df2-f892fb9aae77",
   "metadata": {},
   "source": [
    "### Defining New Columns\n",
    "The Frame returned from `FrameGen.all` always contains the event number and the CV weight for all processed events. These are a useful start, but we can define new columns to hold projected or calculated event properties. For example, to hold the neutrino energy for each event. Column generation functions should return the `pn.Frame.missing_datum` flag if the projection in question cannot be applied to a given event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58ca3ac-9757-47d4-a7ae-47328a1535a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------------\n",
      " | evt# | cvw | enu_GeV |\n",
      " ------------------------\n",
      " |    0 |   1 |   2.275 |\n",
      " |    1 |   1 |    14.3 |\n",
      " |    2 |   1 |    2.86 |\n",
      " |    3 |   1 |   3.728 |\n",
      " |    4 |   1 |    9.08 |\n",
      " |    5 |   1 |   3.237 |\n",
      " |    6 |   1 |   2.473 |\n",
      " |    7 |   1 |   1.916 |\n",
      " |    8 |   1 |   1.988 |\n",
      " |    9 |   1 |   3.671 |\n",
      " ------------------------\n"
     ]
    }
   ],
   "source": [
    "def enu_GeV(ev):\n",
    "    bpart = pps.sel.Beam(ev,14)\n",
    "    if bpart:\n",
    "        return bpart.momentum().e() * 1E-3 # events are always with MeV momentum units\n",
    "    return pn.Frame.missing_datum\n",
    "\n",
    "print(pn.FrameGen(evs).limit(10).add_column(\"enu_GeV\",enu_GeV).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25d71b-6ebd-4e30-ada0-ba6bb07e7a07",
   "metadata": {},
   "source": [
    "### Getting and Modifying Existing Columns\n",
    "\n",
    "Column indices can be searched for or accessed by name. A static sentinal value is returned to flag non-existant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30897c30-026b-47a5-b713-9bc4c6b9e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index for \"enu_GeV\" = 2\n",
      "column index for \"foobar\" = 4294967295, == pn.Frame.npos: True\n"
     ]
    }
   ],
   "source": [
    "fr = pn.FrameGen(evs).limit(10).add_column(\"enu_GeV\",enu_GeV).all()\n",
    "print(\"column index for \\\"enu_GeV\\\" = %s\" % fr.find_column_index(\"enu_GeV\"))\n",
    "print(\"column index for \\\"foobar\\\" = %s, == pn.Frame.npos: %s\" % (fr.find_column_index(\"foobar\"),fr.find_column_index(\"foobar\") == pn.Frame.npos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76771590-042c-4a91-b959-1b7a182b19a8",
   "metadata": {},
   "source": [
    "Using the index operator, `fr[\"colname\"]` returns a reference to a column, so the values can be modified in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b53f5f0-76b1-4a47-9685-580316b2e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "  ------------------------\n",
      " | evt# | cvw | enu_GeV |\n",
      " ------------------------\n",
      " |    0 |   1 |   2.275 |\n",
      " |    1 |   1 |    14.3 |\n",
      " |    2 |   1 |    2.86 |\n",
      " |    3 |   1 |   3.728 |\n",
      " |    4 |   1 |    9.08 |\n",
      " |    5 |   1 |   3.237 |\n",
      " |    6 |   1 |   2.473 |\n",
      " |    7 |   1 |   1.916 |\n",
      " |    8 |   1 |   1.988 |\n",
      " |    9 |   1 |   3.671 |\n",
      " ------------------------\n",
      "After *= 2\n",
      "  ------------------------\n",
      " | evt# | cvw | enu_GeV |\n",
      " ------------------------\n",
      " |    0 |   1 |    4.55 |\n",
      " |    1 |   1 |    28.6 |\n",
      " |    2 |   1 |    5.72 |\n",
      " |    3 |   1 |   7.457 |\n",
      " |    4 |   1 |   18.16 |\n",
      " |    5 |   1 |   6.475 |\n",
      " |    6 |   1 |   4.946 |\n",
      " |    7 |   1 |   3.832 |\n",
      " |    8 |   1 |   3.975 |\n",
      " |    9 |   1 |   7.343 |\n",
      " ------------------------\n",
      "After sqrt\n",
      "  ------------------------\n",
      " | evt# | cvw | enu_GeV |\n",
      " ------------------------\n",
      " |    0 |   1 |   2.133 |\n",
      " |    1 |   1 |   5.348 |\n",
      " |    2 |   1 |   2.392 |\n",
      " |    3 |   1 |   2.731 |\n",
      " |    4 |   1 |   4.261 |\n",
      " |    5 |   1 |   2.545 |\n",
      " |    6 |   1 |   2.224 |\n",
      " |    7 |   1 |   1.958 |\n",
      " |    8 |   1 |   1.994 |\n",
      " |    9 |   1 |    2.71 |\n",
      " ------------------------\n"
     ]
    }
   ],
   "source": [
    "fr = pn.FrameGen(evs).limit(10).add_column(\"enu_GeV\",enu_GeV).all()\n",
    "print(\"Original\\n\",fr)\n",
    "# modify the original frame\n",
    "fr[\"enu_GeV\"] *= 2\n",
    "print(\"After *= 2\\n\",fr)\n",
    "\n",
    "# can use numpy operations on the column objects\n",
    "import numpy as np\n",
    "fr[\"enu_GeV\"] = np.sqrt(fr[\"enu_GeV\"])\n",
    "print(\"After sqrt\\n\",fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb038069-7437-4c27-a5ec-f340dc343290",
   "metadata": {},
   "source": [
    "Column names that are valid attribute names can also be referenced with the attribute syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982e67b1-de04-4d6c-afd8-ff29304dfb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  [ 2.27487048 14.30072308  2.86011408  3.72836792  9.07992245  3.23726147\n",
      "  2.47278658  1.91614913  1.98767289  3.67133838]\n",
      "After += 1:  [ 3.27487048 15.30072308  3.86011408  4.72836792 10.07992245  4.23726147\n",
      "  3.47278658  2.91614913  2.98767289  4.67133838]\n"
     ]
    }
   ],
   "source": [
    "fr = pn.FrameGen(evs).limit(10).add_column(\"enu_GeV\",enu_GeV).all()\n",
    "print(\"Original: \", fr.enu_GeV)\n",
    "fr.enu_GeV += 1\n",
    "print(\"After += 1: \", fr.enu_GeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a78d0-bb47-4a07-a3c5-a6d3de839b78",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "We can apply filters in a similar way to the batched loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3547fee4-d63c-4fea-b4f8-7b05e8bc84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------------\n",
      " | evt# | cvw | enu_GeV |\n",
      " ------------------------\n",
      " |    0 |   1 |   2.275 |\n",
      " |    5 |   1 |   3.237 |\n",
      " |   10 |   1 |   2.506 |\n",
      " |   15 |   1 |   2.682 |\n",
      " |   20 |   1 |   1.528 |\n",
      " |   25 |   1 |   3.214 |\n",
      " |   30 |   1 |   3.033 |\n",
      " |   35 |   1 |   2.014 |\n",
      " |   40 |   1 |   14.87 |\n",
      " |   45 |   1 |   1.661 |\n",
      " ------------------------\n"
     ]
    }
   ],
   "source": [
    "print(pn.FrameGen(evs).limit(50).filter(lambda x : not (x.event_number() % 5)).add_column(\"enu_GeV\",enu_GeV).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba55cbb-83c1-4e69-9bb6-8d12713245e2",
   "metadata": {},
   "source": [
    "## Chunked Processing\n",
    "\n",
    "For long-running processes that would produce very large data frames it might be better to do secondary processing on chunks of the full data frame rather than waiting for the whole thing to be ready. Internally, `FrameGen::all` calls `FrameGen::first` and then `FrameGen::next` until there are no more events in the input event stream to process to new rows. We can steer this chunked processing loop manually in the python. \n",
    "\n",
    "The chunk size can be set with the second parameter to the FrameGen constructor and it defaults to 50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083dbd90-b7d7-47fe-ac7b-fea7b1b954ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 100 new rows, total fetched: 100\n",
      "fetched 100 new rows, total fetched: 200\n",
      "fetched 100 new rows, total fetched: 300\n",
      "fetched 100 new rows, total fetched: 400\n",
      "processed 400 rows in total\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100\n",
    "fg = pn.FrameGen(evs,chunk_size).limit(4*chunk_size)\n",
    "\n",
    "chunk = fg.first()\n",
    "nrows = 0\n",
    "while chunk.rows() > 0:\n",
    "    nrows += chunk.rows()\n",
    "    print(\"fetched %s new rows, total fetched: %s\" % (chunk.rows(), nrows))\n",
    "    chunk = fg.next()\n",
    "\n",
    "print(\"processed %s rows in total\" % nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befae28e-75b3-47b3-a9b2-85ded4feb8d7",
   "metadata": {},
   "source": [
    "**N.B.** `FrameGen::limit` limits the number of events read from the event stream, but the `chunk_size` limits the number of rows returned per call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02481c9e-3c2f-44b9-974a-bd691c8251a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 74 new rows, total fetched: 74\n",
      "fetched 74 new rows, total fetched: 148\n",
      "fetched 74 new rows, total fetched: 222\n",
      "fetched 25 new rows, total fetched: 247\n",
      "processed 247 rows in total, total events read 740\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 74\n",
    "fg = pn.FrameGen(evs,chunk_size).filter(lambda x : not (x.event_number() % 3)).limit(10*chunk_size)\n",
    "\n",
    "chunk = fg.first()\n",
    "nrows = 0\n",
    "while chunk.rows() > 0:\n",
    "    nrows += chunk.rows()\n",
    "    print(\"fetched %s new rows, total fetched: %s\" % (chunk.rows(), nrows))\n",
    "    chunk = fg.next()\n",
    "\n",
    "print(\"processed %s rows in total, total events read %s\" % (nrows,chunk.nevents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f76744-111a-4bc6-97c5-589b8c0fa2e1",
   "metadata": {},
   "source": [
    "**N.B.B** If you request a chunk, you must always process every row in the chunk before breaking out of your processing loop early, or the normalization information from the last chunk will not correspond to the number of rows that you processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed56b2-11e7-47b9-b3a3-fb20d3bcadd6",
   "metadata": {},
   "source": [
    "## Arrow and Pandas\n",
    "\n",
    "If NUISANCE has been built with Apache Arrow support then `FrameGen` can also produce `arrow::RecordBatch` instances. See pyarrow documentation for [`RecordBatches`](https://arrow.apache.org/docs/python/generated/pyarrow.RecordBatch.html).\n",
    "\n",
    "You can query if this copy of NUISANCE has Arrow support like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6231481d-f3d1-4ebf-aa25-6fa745e9ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(pn.FrameGen.has_arrow_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6ca98-9b8c-4774-a5ed-874839deaa30",
   "metadata": {},
   "source": [
    "A key difference between `nuis::Frame` and `arrow::RecordBatch` is that `RecordBatch` instances can have different columns of different types, whereas a `Frame`, which is backed by a single `Eigen::ArrayXXd` always has storage type `double`. But, as you can see in the print out below, the \"event number\" column in the `RecordBatch` is of type `int64`. More integer-typed columns can be added with the `FrameGen.add_int_column` and `FrameGen.add_int_columns` functions. `FrameGen.add_column` is actually just shorthand for `FrameGen.add_double_column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ba3ee9-59e6-4d7b-88b7-163ae02aac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.RecordBatch\n",
      "event number: int64\n",
      "cv weight: double\n",
      "fatx estimate: double\n",
      "enu_GeV: double\n",
      "number of protons: int64\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "chunk_size = 100\n",
    "\n",
    "def enu_GeV(ev):\n",
    "    bpart = pps.sel.Beam(ev,14)\n",
    "    if bpart:\n",
    "        return bpart.momentum().e() * 1E-3 # events are always with MeV momentum units\n",
    "    return pn.Frame.missing_datum\n",
    "\n",
    "def nprotons(ev):\n",
    "    return len(pps.sel.OutParts(ev,2212))\n",
    "\n",
    "fg = pn.FrameGen(evs,chunk_size) \\\n",
    "    .add_column(\"enu_GeV\",enu_GeV) \\\n",
    "    .add_int_column(\"number of protons\",nprotons) \\\n",
    "    .limit(4*chunk_size)\n",
    "\n",
    "chunk = fg.firstArrow()\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a2851-256b-4820-91eb-80936b90cd4b",
   "metadata": {},
   "source": [
    "Because the `RecordBatch` instances are also meant to be saved to disk for later analysis, decoupled from the original input event vector, a column including the running estimate of the fatx per event row is also included.\n",
    "\n",
    "Arrow also provides first class support for Pandas integration. So if you prefer doing analysis with a Pandas DataFrame, you can get one from `FrameGen` in one line of python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57288da2-ca62-4504-a6b4-86b4eb1e0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    event number  cv weight  fatx estimate    enu_GeV  number of protons\n",
      "0              0        1.0        1.05628   2.274870                  1\n",
      "1              1        1.0        1.05628  14.300723                  3\n",
      "2              2        1.0        1.05628   2.860114                  1\n",
      "3              3        1.0        1.05628   3.728368                  1\n",
      "4              4        1.0        1.05628   9.079922                  1\n",
      "..           ...        ...            ...        ...                ...\n",
      "95            95        1.0        1.05628   4.751948                  1\n",
      "96            96        1.0        1.05628   2.102326                  2\n",
      "97            97        1.0        1.05628   2.143340                  2\n",
      "98            98        1.0        1.05628  16.579393                  1\n",
      "99            99        1.0        1.05628   3.194466                  1\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = chunk.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67105341-916c-4b38-809f-b15591bd3488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
